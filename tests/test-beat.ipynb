{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Test beat tracking approaches\n",
    "Tests were done on 31 songs, information about them can be found in file `data.json`.\n",
    "For testing, methods from `detect.py` were used. \n",
    "\n",
    "Each generated file with beat track was then played to check if the beat track actually aligns with beats."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33791f089df4c562"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile as wav\n",
    "import librosa\n",
    "import RhythmRecognition.detect\n",
    "from RhythmRecognition.constants import *\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "f = open('data.json')\n",
    "songs = json.load(f)\n",
    "f.close()\n",
    "path = \"../audio_files/\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# method for creating a wav file with beat track\n",
    "def save(signal, beat_track, filename):\n",
    "    beat_track = librosa.clicks(times=beat_track, sr=SAMPLING_RATE, length=len(signal), hop_length=HOP_LENGTH)\n",
    "    combined = signal + beat_track\n",
    "    wav.write(filename, SAMPLING_RATE, combined.astype(signal.dtype))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "68448e3487a0b93e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Beat track will be generated using known tempo (it will not be calculated using any of the tempogram methods) so we can be sure that the used tempo is correct. If the generated beat track will be bad, it will not be caused by an incorrectly calculated tempo."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d7b66dcf5569169"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "duration = 40  # how many seconds of the song should be loaded (this is just for faster run, we could definitely just load the whole song, but then the processing will take much longer)\n",
    "\n",
    "for i in range(len(songs)):\n",
    "    print(i, \"/\", len(songs), sep=\"\", end=\", \")\n",
    "    song = songs[i]\n",
    "    audiofile = path + song[\"filename\"]\n",
    "    \n",
    "    signal, _ = librosa.load(audiofile, duration=duration, sr=SAMPLING_RATE)  # load the audio file\n",
    "    \n",
    "    # generate and save beat track for score-based beat tracking over spectral novelty function\n",
    "    beat_track = RhythmRecognition.detect.beat_track(audiofile, bpm=song[\"tempo\"], approach=\"score\",novelty_approach=\"spectral\")\n",
    "    save(signal, beat_track, \"out/beat/score/spectral/\" + song[\"name\"] + str(i) +\".wav\")\n",
    "\n",
    "    # generate and save beat track for score-based beat tracking over energy novelty function\n",
    "    beat_track = RhythmRecognition.detect.beat_track(audiofile, bpm=song[\"tempo\"], approach=\"score\", novelty_approach=\"energy\")\n",
    "    save(signal, beat_track, \"out/beat/score/energy/\" + song[\"name\"] + str(i) +\".wav\")\n",
    "\n",
    "    # generate and save beat track for penalty-based beat tracking over spectral novelty function\n",
    "    beat_track = RhythmRecognition.detect.beat_track(audiofile, bpm=song[\"tempo\"], approach=\"penalty\", \n",
    "                                                     novelty_approach=\"spectral\")\n",
    "    save(signal, beat_track, \"out/beat/penalty/spectral/\" + song[\"name\"]+ str(i) +\".wav\")\n",
    "\n",
    "    # generate and save beat track for penalty-based beat tracking over energy novelty function\n",
    "    beat_track = RhythmRecognition.detect.beat_track(audiofile, bpm=song[\"tempo\"], approach=\"penalty\", \n",
    "                                                     novelty_approach=\"energy\")\n",
    "    save(signal, beat_track, \"out/beat/penalty/energy/\" + song[\"name\"] + str(i) +\".wav\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1a1133df06be830b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Beat tracking results\n",
    "After listening to all generated files, I gave each file one of the following three values:\n",
    "* **ok** - if the generated beat track aligned with beats\n",
    "* **half** - if the generated beat clicks were right in the middle of two actual beats, so the found time shift was exactly half of the correct beat time shift\n",
    "* *no** - if the beat track was completely wrong\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4a95604f08329ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "beat_df = pd.read_csv(\"beat_results.csv\")\n",
    "beat_df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b9546c09fdea3bbf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(songs)):\n",
    "    print(i, \"/\", len(songs), sep=\"\", end=\", \")\n",
    "    song = songs[i]\n",
    "    audiofile = path + song[\"filename\"]\n",
    "    \n",
    "    signal, _ = librosa.load(audiofile, duration=duration, sr=SAMPLING_RATE)  # load the audio file\n",
    "    \n",
    "    # generate and save beat track for score-based beat tracking over spectral novelty function\n",
    "\n",
    "    song[\"score-energy\"] = RhythmRecognition.detect.beat_time_shift(audiofile, bpm=song[\"tempo\"], approach=\"score\", novelty_approach=\"energy\")\n",
    "\n",
    "    song[\"penalty-energy\"] = RhythmRecognition.detect.beat_time_shift(audiofile, bpm=song[\"tempo\"], approach=\"penalty\", \n",
    "                                                     novelty_approach=\"energy\")\n",
    "    song[\"score-spectral\"] = RhythmRecognition.detect.beat_time_shift(audiofile, bpm=song[\"tempo\"], approach=\"score\",novelty_approach=\"spectral\")\n",
    "    song[\"penalty-spectral\"] = RhythmRecognition.detect.beat_time_shift(audiofile, bpm=song[\"tempo\"], approach=\"penalty\", \n",
    "                                                     novelty_approach=\"spectral\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "33bb1ea8f491dbce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(songs)\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "55ae072b1a228800"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "20936e7cdfa4ec1b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
