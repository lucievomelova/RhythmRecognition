window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "RhythmRecognition", "modulename": "RhythmRecognition", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.beat", "modulename": "RhythmRecognition.beat", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.beat.beat_tracker", "modulename": "RhythmRecognition.beat.beat_tracker", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker", "kind": "class", "doc": "<p>Base class for specific beat tracking approaches.</p>\n\n<p><strong>Beat</strong> is specified by two parameters: the phase and the period.\nThe period <em>p</em> is given by the reciprocal of the tempo.\nThe phase <em>s</em> then specifies a time shift. The beat function is a sinusoid with period p shifted by s.</p>\n\n<p>Beat tracking is a complex process. First step is extracting peaks from the novelty function of the input signal.\nThen we need to compute the beat period and phase. Period is easily computed from tempo, but computing phase</p>\n\n<ul>\n<li>or the time shift in other words - is more complicated. The different child classes of BeatTracker offer\ndifferent approaches for finding time shift.</li>\n</ul>\n"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.__init__", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>tempo</strong>:  Tempo (in BPM) of the input song.</li>\n<li><strong>duration</strong>:  Duration of the input song in seconds.</li>\n<li><strong>alpha</strong>:  Parameter for peak picking specifying the ratio for how many peaks should be extracted\nfrom the novelty function. The base is (tempo/60) * duration.</li>\n<li><strong>part_len_seconds</strong>:  Peak picking is done on smaller parts of the song. This parameter specifies\nthe part length in seconds.</li>\n<li><strong>min_delta</strong>:  Delta specifies the threshold for peak picking. Peak picking algorithm slowly makes delta\nsmaller so that the correct number of peaks is extracted. When delta reaches min_delta, the algorithm\nends even before finding the desired number of peaks.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.5</span>,</span><span class=\"param\">\t<span class=\"n\">part_len_seconds</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">min_delta</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span></span>)</span>"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.novelty_function", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.novelty_function", "kind": "variable", "doc": "<p>Novelty function of the input audio signal.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.len_frames", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.len_frames", "kind": "variable", "doc": "<p>Length of novelty function in frames.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.frame_times", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.frame_times", "kind": "variable", "doc": "<p>Time of each frame.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.tempo", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.tempo", "kind": "variable", "doc": "<p>Tempo of the song.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.period", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.period", "kind": "variable", "doc": "<p>Length of beat period.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.alpha", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.alpha", "kind": "variable", "doc": "<p>Parameter for peak picking specifying the ratio for how many peaks minimum should be extracted\nfrom the novelty function. The base is (tempo/60) * duration, alpha then specifies the number by \nwhich the base should be multiplied.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.time_shift", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.time_shift", "kind": "variable", "doc": "<p>Time shift of the beat sinusoid from the start.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.duration", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.duration", "kind": "variable", "doc": "<p>Duration of the song in seconds.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.part_len_seconds", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.part_len_seconds", "kind": "variable", "doc": "<p>Length of part in seconds. Peak picking will be done on smaller parts of the song of the specified length.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.min_delta", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.min_delta", "kind": "variable", "doc": "<p>Minimum delta for peak picking. Peak picking algorithm slowly makes delta\nsmaller so that the correct number of peaks is extracted. When delta reaches min_delta, the algorithm\nends even before finding the minimal number of peaks.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.click_times_sec", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.click_times_sec", "kind": "variable", "doc": "<p>Click times. They represent a metronome set to the defined tempo that is started from time 0. Beat tracking \nworks by shifting these click times and finding the best time shift so that the most click time align with \nnote onset candidates.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.peaks", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.peaks", "kind": "variable", "doc": "<p>Peaks in novelty function (their frame position). Peaks represent note onset candidates.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.peak_times", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.peak_times", "kind": "variable", "doc": "<p>Peak times in seconds.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.get_time_shift", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.get_time_shift", "kind": "function", "doc": "<p>Get time shift (beat phase) in seconds.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.beat.beat_tracker.BeatTracker.get_beat_track", "modulename": "RhythmRecognition.beat.beat_tracker", "qualname": "BeatTracker.get_beat_track", "kind": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.beat.click_track", "modulename": "RhythmRecognition.beat.click_track", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.beat.click_track.shift_click_track", "modulename": "RhythmRecognition.beat.click_track", "qualname": "shift_click_track", "kind": "function", "doc": "<p>Shift click track by specified time shift.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">len_frames</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">click_track</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">time_shift</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.beat.click_track.get_click_times_sec", "modulename": "RhythmRecognition.beat.click_track", "qualname": "get_click_times_sec", "kind": "function", "doc": "<p>Get click times in seconds</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>tempo</strong>:  Tempo in BPM.</li>\n<li><strong>duration</strong>:  Duration in seconds.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Click times (in seconds).</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tempo</span>, </span><span class=\"param\"><span class=\"n\">duration</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.beat.click_track.get_click_times_frames", "modulename": "RhythmRecognition.beat.click_track", "qualname": "get_click_times_frames", "kind": "function", "doc": "<p>Get click times in frames.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>tempo</strong>:  Tempo in BPM.</li>\n<li><strong>duration</strong>:  Duration in seconds.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Click times (in frames).</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">tempo</span>, </span><span class=\"param\"><span class=\"n\">duration</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span> <span class=\"o\">|</span> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.beat.peak_picking", "modulename": "RhythmRecognition.beat.peak_picking", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.beat.peak_picking.extract_part_from_novelty", "modulename": "RhythmRecognition.beat.peak_picking", "qualname": "extract_part_from_novelty", "kind": "function", "doc": "<p>Extract only specific part of novelty function and set everything else to 0.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input signal.</li>\n<li><strong>part_len</strong>:  Length of part in frames.</li>\n<li><strong>part_number</strong>:  Index of current part (-1 for last part).</li>\n<li><strong>parts</strong>:  Total number of parts.</li>\n<li><strong>last_part_len</strong>:  Length of last part.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Novelty function where everything except for part is set to 0.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">part_len</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">part_number</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">parts</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">last_part_len</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.beat.peak_picking.peak_pick_from_part", "modulename": "RhythmRecognition.beat.peak_picking", "qualname": "peak_pick_from_part", "kind": "function", "doc": "<p>Extract peaks from specified part of the novelty function.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>part</strong>:  Part of novelty function</li>\n<li><strong>delta</strong>:  Threshold for mean for peak picking</li>\n<li><strong>min_number_of_peaks_in_part</strong>:  Minimum number of extracted peaks</li>\n<li><strong>min_delta</strong>:  Minimum delta value. After reaching this value for delta, the method will return even if\nit didn't find enough peaks.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Peaks in part.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">part</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">delta</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">min_number_of_peaks_in_part</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">min_delta</span><span class=\"p\">:</span> <span class=\"nb\">float</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.beat.peak_picking.peak_pick", "modulename": "RhythmRecognition.beat.peak_picking", "qualname": "peak_pick", "kind": "function", "doc": "<p>Extract peaks by dividing the novelty function into parts and finding peaks in each part separately.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input signal.</li>\n<li><strong>duration</strong>:  Duration in seconds.</li>\n<li><strong>min_number_of_peaks</strong>:  Minimum number of peaks that should be picked.</li>\n<li><strong>part_len_seconds</strong>:  Length of one part in seconds</li>\n<li><strong>min_delta</strong>:  Minimum value of delta for peak picking. After that, the algorithm will end even if it\ndoesn't find at least min_number_of_peaks peaks</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Peak times in frames</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">min_number_of_peaks</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">part_len_seconds</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">min_delta</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.beat.penalty", "modulename": "RhythmRecognition.beat.penalty", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.beat.penalty.PenaltyBeatTracker", "modulename": "RhythmRecognition.beat.penalty", "qualname": "PenaltyBeatTracker", "kind": "class", "doc": "<p>Beat tracker based on scores with penalty.</p>\n\n<p>Beat tracking will be based trying out all possible time shifts and assigning score points to shifted time clicks.\nBut instead of simply awarding 0 or 1 score point, we will awards a number of points based on how far the closest\nnote onset candidate is from current time click. The closer the candidate is, the more\npoints it gets. To do that, we will use a penalty function.\nAfter trying all possible time shifts, we will choose time shift with the highest score.</p>\n", "bases": "RhythmRecognition.beat.beat_tracker.BeatTracker"}, {"fullname": "RhythmRecognition.beat.penalty.PenaltyBeatTracker.__init__", "modulename": "RhythmRecognition.beat.penalty", "qualname": "PenaltyBeatTracker.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>tempo</strong>:  Tempo (in BPM) of the input song.</li>\n<li><strong>duration</strong>:  Duration of the input song in seconds.</li>\n<li><strong>alpha</strong>:  Parameter for peak picking specifying the ratio for how many peaks should be extracted\nfrom the novelty function. The base is (tempo/60) * duration.</li>\n<li><strong>part_len_seconds</strong>:  Peak  picking is done on smaller parts of the song. This parameter specifies\nthe part length in seconds.</li>\n<li><strong>min_delta</strong>:  Delta specifies the threshold for peak picking. Peak picking algorithm slowly makes delta\nsmaller so that the correct number of peaks is extracted. When delta reaches min_delta, the algorithm\nends even before finding the desired number of peaks.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.5</span>,</span><span class=\"param\">\t<span class=\"n\">part_len_seconds</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">min_delta</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span></span>)</span>"}, {"fullname": "RhythmRecognition.beat.score", "modulename": "RhythmRecognition.beat.score", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.beat.score.ScoreBeatTracker", "modulename": "RhythmRecognition.beat.score", "qualname": "ScoreBeatTracker", "kind": "class", "doc": "<p>Beat tracker based on score.</p>\n\n<p>Beat tracking will be based trying out all possible time shifts and assigning score points to shifted time clicks.\nWe will assign 1 score point to each shifted time click that is close to a note onset candidate (how close\na candidate needs to be will be defined by the tolerance interval).\nAfter trying all possible time shifts, we will choose time shift with the highest score.</p>\n", "bases": "RhythmRecognition.beat.beat_tracker.BeatTracker"}, {"fullname": "RhythmRecognition.beat.score.ScoreBeatTracker.__init__", "modulename": "RhythmRecognition.beat.score", "qualname": "ScoreBeatTracker.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>tempo</strong>:  Tempo (in BPM) of the input song.</li>\n<li><strong>duration</strong>:  Duration of the input song in seconds.</li>\n<li><strong>tolerance_interval</strong>:  Length of tolerance interval in milliseconds.</li>\n<li><strong>alpha</strong>:  Parameter for peak picking specifying the ratio for how many peaks should be extracted\nfrom the novelty function. The base is (tempo/60) * duration.</li>\n<li><strong>part_len_seconds</strong>:  Peak  picking is done on smaller parts of the song. This parameter specifies\nthe part length in seconds.</li>\n<li><strong>min_delta</strong>:  Delta specifies the threshold for peak picking. Peak picking algorithm slowly makes delta\nsmaller so that the correct number of peaks is extracted. When delta reaches min_delta, the algorithm\nends even before finding the desired number of peaks.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">tolerance_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.5</span>,</span><span class=\"param\">\t<span class=\"n\">part_len_seconds</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">min_delta</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span></span>)</span>"}, {"fullname": "RhythmRecognition.beat.score.ScoreBeatTracker.tolerance", "modulename": "RhythmRecognition.beat.score", "qualname": "ScoreBeatTracker.tolerance", "kind": "variable", "doc": "<p>Length of tolerance interval in milliseconds for scoring.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.constants", "modulename": "RhythmRecognition.constants", "kind": "module", "doc": "<p>Constants used for audio file processing.</p>\n"}, {"fullname": "RhythmRecognition.constants.FRAME_LENGTH", "modulename": "RhythmRecognition.constants", "qualname": "FRAME_LENGTH", "kind": "variable", "doc": "<p><strong>Frame length</strong> specifies the number of samples in a frame.\nThe input signal is cut into smaller frames (of this size) and calculations are done over them.</p>\n", "default_value": "2048"}, {"fullname": "RhythmRecognition.constants.HOP_LENGTH", "modulename": "RhythmRecognition.constants", "qualname": "HOP_LENGTH", "kind": "variable", "doc": "<p><strong>Hop length</strong> refers to the number of samples by which we have to advance between two consecutive frames. \nIn other words, it determines the overlap between frames.</p>\n", "default_value": "1024"}, {"fullname": "RhythmRecognition.constants.SAMPLING_RATE", "modulename": "RhythmRecognition.constants", "qualname": "SAMPLING_RATE", "kind": "variable", "doc": "<p><strong>Sampling rate</strong> specifies the number of samples per second that were take from a continuous signal to \nmake a discrete signal. This sampling rate (so 44.1 kHz) is the standard sampling rate for audio formats.</p>\n", "default_value": "44100"}, {"fullname": "RhythmRecognition.constants.SEGMENT_LENGTH_SECONDS", "modulename": "RhythmRecognition.constants", "qualname": "SEGMENT_LENGTH_SECONDS", "kind": "variable", "doc": "<p>Length of segment in seconds for calculating segment-level features.</p>\n", "default_value": "8"}, {"fullname": "RhythmRecognition.constants.SEGMENT_LENGTH", "modulename": "RhythmRecognition.constants", "qualname": "SEGMENT_LENGTH", "kind": "variable", "doc": "<p>Length of segment in frames for calculating segment-level features.</p>\n", "default_value": "352800"}, {"fullname": "RhythmRecognition.detect", "modulename": "RhythmRecognition.detect", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.detect.NOVELTY", "modulename": "RhythmRecognition.detect", "qualname": "NOVELTY", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;energy&#x27;, &#x27;spectral&#x27;]"}, {"fullname": "RhythmRecognition.detect.TEMPO", "modulename": "RhythmRecognition.detect", "qualname": "TEMPO", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;fourier&#x27;, &#x27;autocorrelation&#x27;, &#x27;hybrid&#x27;]"}, {"fullname": "RhythmRecognition.detect.BEAT", "modulename": "RhythmRecognition.detect", "qualname": "BEAT", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;score&#x27;, &#x27;penalty&#x27;]"}, {"fullname": "RhythmRecognition.detect.RHYTHM", "modulename": "RhythmRecognition.detect", "qualname": "RHYTHM", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;parts&#x27;, &#x27;chorus-verse&#x27;]"}, {"fullname": "RhythmRecognition.detect.novelty_function", "modulename": "RhythmRecognition.detect", "qualname": "novelty_function", "kind": "function", "doc": "<p>Compute novelty function of the given song.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  Name of the input audio file.</li>\n<li><strong>approach</strong>:  Which novelty function to compute - options are spectral or energy.</li>\n<li><strong>duration</strong>:  Duration of the song in seconds. Only specify this parameter if you need to use a smaller\npart of the song. If not specified, it is set to the whole song duration.</li>\n<li><strong>gamma</strong>:  Compression factor for logarithmic compression.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Computed novelty function.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audiofile</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;spectral&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.detect.tempo", "modulename": "RhythmRecognition.detect", "qualname": "tempo", "kind": "function", "doc": "<p>Get dominant tempo of the given song.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  Name of the input audio file.</li>\n<li><strong>approach</strong>:  Which tempogram to use - options are fourier, autocorrelation or hybrid.</li>\n<li><strong>novelty_approach</strong>:  Which novelty function to compute - options are spectral or energy.</li>\n<li><strong>duration</strong>:  Duration of the song in seconds. Only specify this parameter if you need to use a smaller\npart of the song. If not specified, it is set to the whole song duration.</li>\n<li><strong>novelty_gamma</strong>:  Compression factor for logarithmic compression used for computing the novelty function.</li>\n<li><strong>similarity</strong>:  BPM tolerance that specifies which BPM values belong to the same group.</li>\n<li><strong>number_of_dominant_values</strong>:  How many dominant BPM values should be extracted for later computations.</li>\n<li><strong>lower_bound</strong>:  Lowest possible BPM value that will be considered.</li>\n<li><strong>upper_bound</strong>:  Highest possible BPM value that will be considered.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Most dominant tempo value (in BPM).</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audiofile</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;fourier&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;spectral&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_gamma</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">similarity</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">number_of_dominant_values</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">lower_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">200</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.detect.tempogram", "modulename": "RhythmRecognition.detect", "qualname": "tempogram", "kind": "function", "doc": "<p>Get tempogram of the given song.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  Name of the input audio file.</li>\n<li><strong>approach</strong>:  Which tempogram to use - options are fourier, autocorrelation or hybrid.</li>\n<li><strong>novelty_approach</strong>:  Which novelty function to compute - options are spectral or energy.</li>\n<li><strong>duration</strong>:  Duration of the song in seconds. Only specify this parameter if you need to use a smaller\npart of the song. If not specified, it is set to the whole song duration.</li>\n<li><strong>novelty_gamma</strong>:  Compression factor for logarithmic compression used for computing the novelty function.</li>\n<li><strong>similarity</strong>:  BPM tolerance that specifies which BPM values belong to the same group.</li>\n<li><strong>number_of_dominant_values</strong>:  How many dominant BPM values should be extracted for later computations.</li>\n<li><strong>lower_bound</strong>:  Lowest possible BPM value that will be considered.</li>\n<li><strong>upper_bound</strong>:  Highest possible BPM value that will be considered.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Computed tempogram.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audiofile</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;fourier&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;spectral&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_gamma</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">similarity</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">number_of_dominant_values</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">lower_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">200</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.detect.beat_track", "modulename": "RhythmRecognition.detect", "qualname": "beat_track", "kind": "function", "doc": "<p>Compute beat track for the given song.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  Name of the input audio file.</li>\n<li><strong>approach</strong>:  Which beat tracking approach to use - options are score or penalty.</li>\n<li><strong>tempo_approach</strong>:  Which tempogram to use - options are fourier, autocorrelation or hybrid.</li>\n<li><strong>novelty_approach</strong>:  Which novelty function to compute - options are spectral or energy.</li>\n<li><strong>duration</strong>:  Duration of the song in seconds. Only specify this parameter if you need to use a smaller\npart of the song. If not specified, it is set to the whole song duration.</li>\n<li><strong>novelty_gamma</strong>:  Compression factor for logarithmic compression used for computing the novelty function.</li>\n<li><strong>bpm</strong>:  Tempo of the song. Optional parameter - if it is not specified, tempo will be calculated using\nthe specified tempo analysis approach. If this paramter is specified, all tempo analysis-related parameters\nwill be ignored.</li>\n<li><strong>similarity_tempo</strong>:  BPM tolerance that specifies which BPM values belong to the same group.</li>\n<li><strong>number_of_dominant_values_tempo</strong>:  How many dominant BPM values should be extracted for later computations.</li>\n<li><strong>lower_bound</strong>:  Lowest possible BPM value that will be considered.</li>\n<li><strong>upper_bound</strong>:  Highest possible BPM value that will be considered.</li>\n<li><strong>tolerance_interval</strong>:  Length of tolerance interval in milliseconds.\nOnly used in \"score\" beat tracking approach.</li>\n<li><strong>alpha</strong>:  Parameter for peak picking specifying the ratio for how many peaks should be extracted\nfrom the novelty function. The base is (tempo/60) * duration.</li>\n<li><strong>part_len_seconds</strong>:  Peak  picking is done on smaller parts of the song. This parameter specifies\nthe part length in seconds.</li>\n<li><strong>min_delta</strong>:  Delta specifies the threshold for peak picking. Peak picking algorithm slowly makes delta\nsmaller so that the correct number of peaks is extracted. When delta reaches min_delta, the algorithm\nends even before finding the desired number of peaks.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Array of beat times.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audiofile</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;score&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">tempo_approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;fourier&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;spectral&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_gamma</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">bpm</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">similarity_tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">number_of_dominant_values_tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">lower_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">200</span>,</span><span class=\"param\">\t<span class=\"n\">tolerance_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.5</span>,</span><span class=\"param\">\t<span class=\"n\">part_len_seconds</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">min_delta</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.detect.beat_time_shift", "modulename": "RhythmRecognition.detect", "qualname": "beat_time_shift", "kind": "function", "doc": "<p>Compute beat time shift for the given song. The time shift specifies the time by which we need to shift a click\ntrack set to a found tempo so that it's clicks will align with the song beats.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  Name of the input audio file.</li>\n<li><strong>approach</strong>:  Which beat tracking approach to use - options are score or penalty.</li>\n<li><strong>tempo_approach</strong>:  Which tempogram to use - options are fourier, autocorrelation or hybrid.</li>\n<li><strong>novelty_approach</strong>:  Which novelty function to compute - options are spectral or energy.</li>\n<li><strong>duration</strong>:  Duration of the song in seconds. Only specify this parameter if you need to use a smaller\npart of the song. If not specified, it is set to the whole song duration.</li>\n<li><strong>novelty_gamma</strong>:  Compression factor for logarithmic compression used for computing the novelty function.</li>\n<li><strong>bpm</strong>:  Tempo of the song. Optional parameter - if it is not specified, tempo will be calculated using\nthe specified tempo analysis approach. If this paramter is specified, all tempo analysis-related parameters\nwill be ignored.</li>\n<li><strong>similarity_tempo</strong>:  BPM tolerance that specifies which BPM values belong to the same group.</li>\n<li><strong>number_of_dominant_values_tempo</strong>:  How many dominant BPM values should be extracted for later computations.</li>\n<li><strong>lower_bound</strong>:  Lowest possible BPM value that will be considered.</li>\n<li><strong>upper_bound</strong>:  Highest possible BPM value that will be considered.</li>\n<li><strong>tolerance_interval</strong>:  Length of tolerance interval in milliseconds.\nOnly used in \"score\" beat tracking approach.</li>\n<li><strong>alpha</strong>:  Parameter for peak picking specifying the ratio for how many peaks should be extracted\nfrom the novelty function. The base is (tempo/60) * duration.</li>\n<li><strong>part_len_seconds</strong>:  Peak  picking is done on smaller parts of the song. This parameter specifies\nthe part length in seconds.</li>\n<li><strong>min_delta</strong>:  Delta specifies the threshold for peak picking. Peak picking algorithm slowly makes delta\nsmaller so that the correct number of peaks is extracted. When delta reaches min_delta, the algorithm\nends even before finding the desired number of peaks.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Beat time shift.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audiofile</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;score&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">tempo_approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;fourier&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;spectral&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_gamma</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">bpm</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">similarity_tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">number_of_dominant_values_tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">lower_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">200</span>,</span><span class=\"param\">\t<span class=\"n\">tolerance_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.5</span>,</span><span class=\"param\">\t<span class=\"n\">part_len_seconds</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">min_delta</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">float</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.detect.rhythm_track", "modulename": "RhythmRecognition.detect", "qualname": "rhythm_track", "kind": "function", "doc": "<p>Find rhythmic notes.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  Name of the input audio file.</li>\n<li><strong>approach</strong>:  Which rhythm tracking approach to use - options are score or chorus-verse. Use chorus-verse only\nif the song has significant energy changes between different song parts.</li>\n<li><strong>beat_approach</strong>:  Which beat tracking approach to use - options are score or penalty.</li>\n<li><strong>tempo_approach</strong>:  Which tempogram to use - options are fourier, autocorrelation or hybrid.</li>\n<li><strong>novelty_approach</strong>:  Which novelty function to compute - options are spectral or energy.</li>\n<li><strong>duration</strong>:  Duration of the song in seconds. Only specify this parameter if you need to use a smaller\npart of the song. If not specified, it is set to the whole song duration.</li>\n<li><strong>novelty_gamma</strong>:  Compression factor for logarithmic compression used for computing the novelty function.</li>\n<li><strong>bpm</strong>:  Tempo of the song. Optional parameter - if it is not specified, tempo will be calculated using\nthe specified tempo analysis approach. If this paramter is specified, all tempo analysis-related parameters\nwill be ignored.</li>\n<li><strong>similarity_tempo</strong>:  BPM tolerance that specifies which BPM values belong to the same group.</li>\n<li><strong>number_of_dominant_values_tempo</strong>:  How many dominant BPM values should be extracted for later computations.</li>\n<li><strong>lower_bound</strong>:  Lowest possible BPM value that will be considered.</li>\n<li><strong>upper_bound</strong>:  Highest possible BPM value that will be considered.</li>\n<li><strong>tolerance_beat</strong>:  Length of tolerance interval in milliseconds for beat tracking.\nOnly used in \"score\" beat tracking approach.</li>\n<li><strong>alpha_beat</strong>:  Parameter for peak picking sued in beat tracking specifying the ratio for how many\npeaks should be extracted from the novelty function. The base is (tempo/60) * duration.</li>\n<li><strong>part_len_seconds_beat</strong>:  Peak  picking is done on smaller parts of the song. This parameter specifies\nthe part length in seconds.</li>\n<li><strong>min_delta</strong>:  Delta specifies the threshold for peak picking. Peak picking algorithm slowly makes delta\nsmaller so that the correct number of peaks is extracted. When delta reaches min_delta, the algorithm\nends even before finding the desired number of peaks.</li>\n<li><strong>tolerance_interval</strong>:  Length of tolerance interval in milliseconds.</li>\n<li><p><strong>alpha</strong>:  Parameter for peak picking used in rhythm tracking specifying the ratio for how many peaks\nshould be extracted from the novelty function. The base is (tempo/60) * duration.</p></li>\n<li><p><strong>part_len_seconds</strong>:  Length of song part in seconds. Peak picking will be done on smaller parts\nof the song of the specified length. Only used in \"parts\" rhythm tracking approach.</p></li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Array of rhythmic note onset times.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audiofile</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;parts&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">beat_approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;score&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">tempo_approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;fourier&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_approach</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"s1\">&#39;spectral&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_gamma</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">bpm</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">similarity_tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">number_of_dominant_values_tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">lower_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">200</span>,</span><span class=\"param\">\t<span class=\"n\">tolerance_beat</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">alpha_beat</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.5</span>,</span><span class=\"param\">\t<span class=\"n\">part_len_seconds_beat</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">min_delta</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mf\">1e-05</span>,</span><span class=\"param\">\t<span class=\"n\">tolerance_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">part_len_seconds</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">20</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.math", "modulename": "RhythmRecognition.math", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.math.logarithmic_compression", "modulename": "RhythmRecognition.math", "qualname": "logarithmic_compression", "kind": "function", "doc": "<p>Logarithmic compression: L(x) = log(1+gamma*x).</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>x</strong>:  Function to compress.</li>\n<li><strong>gamma</strong>:  Compression factor.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>, </span><span class=\"param\"><span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.math.first_order_diff", "modulename": "RhythmRecognition.math", "qualname": "first_order_diff", "kind": "function", "doc": "<p>First-order diference (or discrete derivative) - calculate difference between two subsequent energy values</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.math.half_wave_rectification", "modulename": "RhythmRecognition.math", "qualname": "half_wave_rectification", "kind": "function", "doc": "<p>Half-wave rectification - keep only positive values.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.math.rmse", "modulename": "RhythmRecognition.math", "qualname": "rmse", "kind": "function", "doc": "<p>Compute root-mean-square energy of the signal.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">x</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>, </span><span class=\"param\"><span class=\"n\">frame_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span>, </span><span class=\"param\"><span class=\"n\">hop_length</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.onset", "modulename": "RhythmRecognition.onset", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.onset.novelty_function", "modulename": "RhythmRecognition.onset.novelty_function", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.onset.novelty_function.NoveltyFunction", "modulename": "RhythmRecognition.onset.novelty_function", "qualname": "NoveltyFunction", "kind": "class", "doc": "<p>Base class for specific novelty function implementations.</p>\n\n<p><strong>Novelty function</strong> is a function that\ndenotes local changes in signal properties. When computed from certain signal\nproperties, peaks in novelty function should indicate note onsets</p>\n"}, {"fullname": "RhythmRecognition.onset.novelty_function.NoveltyFunction.__init__", "modulename": "RhythmRecognition.onset.novelty_function", "qualname": "NoveltyFunction.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  Name of the audio file to be processed.</li>\n<li><strong>duration</strong>:  Duration of the song in seconds. Only specify this parameter if you need to use a smaller\npart of the song. If not specified, it is set to the whole song duration.</li>\n<li><strong>gamma</strong>:  Compression factor for logarithmic compression.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">audiofile</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">|</span> <span class=\"kc\">None</span> <span class=\"o\">=</span> <span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">gamma</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span></span>)</span>"}, {"fullname": "RhythmRecognition.onset.novelty_function.NoveltyFunction.signal", "modulename": "RhythmRecognition.onset.novelty_function", "qualname": "NoveltyFunction.signal", "kind": "variable", "doc": "<p>Audio time series.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.onset.novelty_function.NoveltyFunction.duration", "modulename": "RhythmRecognition.onset.novelty_function", "qualname": "NoveltyFunction.duration", "kind": "variable", "doc": "<p>Duration of the song in seconds.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.onset.novelty_function.NoveltyFunction.len_frames", "modulename": "RhythmRecognition.onset.novelty_function", "qualname": "NoveltyFunction.len_frames", "kind": "variable", "doc": "<p>Length of novelty function in frames.</p>\n", "annotation": ": int | None"}, {"fullname": "RhythmRecognition.onset.novelty_function.NoveltyFunction.gamma", "modulename": "RhythmRecognition.onset.novelty_function", "qualname": "NoveltyFunction.gamma", "kind": "variable", "doc": "<p>Compression factor for logarithmic compression.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.onset.novelty_function.NoveltyFunction.novelty_function", "modulename": "RhythmRecognition.onset.novelty_function", "qualname": "NoveltyFunction.novelty_function", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.onset.novelty_function.NoveltyFunction.get", "modulename": "RhythmRecognition.onset.novelty_function", "qualname": "NoveltyFunction.get", "kind": "function", "doc": "<p>Get novelty function of input signal.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.onset.rmse", "modulename": "RhythmRecognition.onset.rmse", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.onset.rmse.EnergyNovelty", "modulename": "RhythmRecognition.onset.rmse", "qualname": "EnergyNovelty", "kind": "class", "doc": "<p>Class for computing energy novelty function based on root-mean-square energy (RMSE).</p>\n\n<p><strong>RMSE</strong> is a time domain feature that contains information about the overall intensity or\nstrength of an audio signal. This approach is based on the assumption that note\nonsets correspond with sudden increases in energy.</p>\n", "bases": "RhythmRecognition.onset.novelty_function.NoveltyFunction"}, {"fullname": "RhythmRecognition.onset.rmse.EnergyNovelty.__init__", "modulename": "RhythmRecognition.onset.rmse", "qualname": "EnergyNovelty.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  Name of the audio file to be processed.</li>\n<li><strong>duration</strong>:  Duration of the song in seconds. Only specify this parameter if you need to use a smaller\npart of the song. If not specified, it is set to the whole song duration.</li>\n<li><strong>gamma</strong>:  Compression factor for logarithmic compression.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">audiofile</span>, </span><span class=\"param\"><span class=\"n\">duration</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mi\">10</span></span>)</span>"}, {"fullname": "RhythmRecognition.onset.rmse.EnergyNovelty.rmse", "modulename": "RhythmRecognition.onset.rmse", "qualname": "EnergyNovelty.rmse", "kind": "variable", "doc": "<p>Root-mean-square energy of the input signal.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.onset.spectral", "modulename": "RhythmRecognition.onset.spectral", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.onset.spectral.SpectralNovelty", "modulename": "RhythmRecognition.onset.spectral", "qualname": "SpectralNovelty", "kind": "class", "doc": "<p>Class for computing spectral novelty function.</p>\n\n<p>The spectral-based novelty function is computed from time-frequency representation of the\nsignal. The idea is that by tracking changes in frequency content of the signal, we can detect note onsets.</p>\n", "bases": "RhythmRecognition.onset.novelty_function.NoveltyFunction"}, {"fullname": "RhythmRecognition.onset.spectral.SpectralNovelty.__init__", "modulename": "RhythmRecognition.onset.spectral", "qualname": "SpectralNovelty.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  filename with the song to be analyzed</li>\n<li><strong>duration</strong>:  duration of the song in seconds, if the whole song shouldn't be used</li>\n<li><strong>gamma</strong>:  compression factor (for logarithmic compression)</li>\n<li><strong>neighborhood_size_sec</strong>:  neighborhood size in seconds for local average computation</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">audiofile</span>, </span><span class=\"param\"><span class=\"n\">duration</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">gamma</span><span class=\"o\">=</span><span class=\"mi\">10</span>, </span><span class=\"param\"><span class=\"n\">neighborhood_size_sec</span><span class=\"o\">=</span><span class=\"mf\">0.1</span></span>)</span>"}, {"fullname": "RhythmRecognition.onset.spectral.SpectralNovelty.neighborhood_size_sec", "modulename": "RhythmRecognition.onset.spectral", "qualname": "SpectralNovelty.neighborhood_size_sec", "kind": "variable", "doc": "<p>Neighborhood size for local normalization in seconds.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.onset.spectral.SpectralNovelty.neighborhood_size_frames", "modulename": "RhythmRecognition.onset.spectral", "qualname": "SpectralNovelty.neighborhood_size_frames", "kind": "variable", "doc": "<p>Neighborhood size for local normalization in frames.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.rhythm", "modulename": "RhythmRecognition.rhythm", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.rhythm.chorus_verse", "modulename": "RhythmRecognition.rhythm.chorus_verse", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.rhythm.chorus_verse.ChorusVerseRhythmTracker", "modulename": "RhythmRecognition.rhythm.chorus_verse", "qualname": "ChorusVerseRhythmTracker", "kind": "class", "doc": "<p>Rhythm tracking for songs based on dividing songs into chorus and verse parts (and possibly other parts).</p>\n\n<p>Song parts are extracted based on root-mean-square energy (RMSE). We will compute RMSE as a segment-level feature\n(in range of seconds). This will give us information about energy of longer parts of the song.\nIn theory, verse should have lower energy than chorus, so there should be very clear changes in the energy\nfunction when going from a verse to a chorus (this should also work for other song part types).</p>\n", "bases": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker"}, {"fullname": "RhythmRecognition.rhythm.chorus_verse.ChorusVerseRhythmTracker.__init__", "modulename": "RhythmRecognition.rhythm.chorus_verse", "qualname": "ChorusVerseRhythmTracker.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>audiofile</strong>:  Name of the audio file to be processed.</li>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>duration</strong>:  Duration of the input song in seconds.</li>\n<li><strong>tempo</strong>:  Tempo in BPM.</li>\n<li><strong>beat_times</strong>:  List of beat times.</li>\n<li><strong>alpha</strong>:  Parameter for peak picking specifying the ratio for how many peaks should be extracted\nfrom the novelty function. The base is (tempo/60) * duration.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">audiofile</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">beat_times</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">tolerance_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mi\">2</span></span>)</span>"}, {"fullname": "RhythmRecognition.rhythm.chorus_verse.ChorusVerseRhythmTracker.signal", "modulename": "RhythmRecognition.rhythm.chorus_verse", "qualname": "ChorusVerseRhythmTracker.signal", "kind": "variable", "doc": "<p>Audio time series.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.rhythm.chorus_verse.ChorusVerseRhythmTracker.compute_segment_rmse", "modulename": "RhythmRecognition.rhythm.chorus_verse", "qualname": "ChorusVerseRhythmTracker.compute_segment_rmse", "kind": "function", "doc": "<p>Compute root-mean-square energy of on segment-level.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.rhythm.chorus_verse.ChorusVerseRhythmTracker.find_song_parts", "modulename": "RhythmRecognition.rhythm.chorus_verse", "qualname": "ChorusVerseRhythmTracker.find_song_parts", "kind": "function", "doc": "<p>Divide song int verse, chorus and other song parts.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Array of points where there is a transition from one part to another.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.rhythm.chorus_verse.ChorusVerseRhythmTracker.find_rhythmic_onsets", "modulename": "RhythmRecognition.rhythm.chorus_verse", "qualname": "ChorusVerseRhythmTracker.find_rhythmic_onsets", "kind": "function", "doc": "<p>Extract rhythmic onsets in the song by dividing it into chorus and verse (and possibly other part types)\nparts and extracting note onsets from each aprt separately.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Rhythmic note onsets.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.rhythm.parts", "modulename": "RhythmRecognition.rhythm.parts", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.rhythm.parts.EqualPartsRhythmTracker", "modulename": "RhythmRecognition.rhythm.parts", "qualname": "EqualPartsRhythmTracker", "kind": "class", "doc": "<p>Rhythm tracking for songs based on dividing songs into equal parts.</p>\n\n<p>If verse and chorus detection cannot be applied, because the song energy changes are not giving any information\nabout part transitions, we will simply divide the song into equal parts and find rhythmic note onsets in each\npart separately.</p>\n", "bases": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker"}, {"fullname": "RhythmRecognition.rhythm.parts.EqualPartsRhythmTracker.__init__", "modulename": "RhythmRecognition.rhythm.parts", "qualname": "EqualPartsRhythmTracker.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>duration</strong>:  Duration of the input song in seconds.</li>\n<li><strong>tempo</strong>:  Tempo in BPM.</li>\n<li><strong>beat_times</strong>:  List of beat times.</li>\n<li><strong>alpha</strong>:  Parameter for peak picking specifying the ratio for how many peaks should be extracted\nfrom the novelty function. The base is (tempo/60) * duration.</li>\n<li><strong>part_len</strong>:  Length of song part in seconds. Peak picking will be done on smaller parts\nof the song of the specified length.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">beat_times</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">tolerance_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">20</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">part_len</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">20</span></span>)</span>"}, {"fullname": "RhythmRecognition.rhythm.parts.EqualPartsRhythmTracker.part_len_seconds", "modulename": "RhythmRecognition.rhythm.parts", "qualname": "EqualPartsRhythmTracker.part_len_seconds", "kind": "variable", "doc": "<p>Length of part in seconds. Peak picking will be done on smaller parts of the song of the specified length.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.rhythm.parts.EqualPartsRhythmTracker.find_rhythmic_onsets", "modulename": "RhythmRecognition.rhythm.parts", "qualname": "EqualPartsRhythmTracker.find_rhythmic_onsets", "kind": "function", "doc": "<p>Extract rhythmic onsets in the song by dividing it into equal parts and extracting\nonsets from each part separately.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>part_len</strong>:  Length of song part</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Rhythmic note onsets.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker", "kind": "class", "doc": "<p>Base class for specific rhythm detection approaches.</p>\n\n<p><strong>Rhythm</strong> is the pattern of sounds, silences, and emphases in a song.\nWe will focus on strong note onsets that are frequently occurring after beats approximately after\nthe same time as other note onsets. To do this, we will calculate score for each distance between\na closest preceding beat and a note onset candidate. Distances with high scores will be\nconsidered as frequently occurring. If a note onset candidate is occuring after a beat and this distance\nhas a high score, this note onset candidate will be considered to be a rhythmic note onset.</p>\n\n<p>Score will be calculated on parts of a song. The specific rhythm tracking approaches differ in\nsong partitioning.</p>\n"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.__init__", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>duration</strong>:  Duration of the input song in seconds.</li>\n<li><strong>tempo</strong>:  Tempo in BPM.</li>\n<li><strong>beat_times</strong>:  List of beat times.</li>\n<li><strong>tolerance_interval</strong>:  Length of tolerance interval in milliseconds.</li>\n<li><strong>alpha</strong>:  Parameter for peak picking specifying the ratio for how many peaks should be extracted\nfrom the novelty function. The base is (tempo/60) * duration.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">duration</span><span class=\"p\">:</span> <span class=\"nb\">float</span>,</span><span class=\"param\">\t<span class=\"n\">tempo</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">beat_times</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">tolerance_interval</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">alpha</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mi\">2</span></span>)</span>"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.novelty_function", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.novelty_function", "kind": "variable", "doc": "<p>Novelty function of the input audio signal.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.len_frames", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.len_frames", "kind": "variable", "doc": "<p>Length of novelty function in frames.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.frame_times", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.frame_times", "kind": "variable", "doc": "<p>Time of each frame.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.tempo", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.tempo", "kind": "variable", "doc": "<p>Tempo of the song.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.period", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.period", "kind": "variable", "doc": "<p>Length of beat period.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.alpha", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.alpha", "kind": "variable", "doc": "<p>Parameter for peak picking specifying the ratio for how many peaks minimum should be extracted\nfrom the novelty function. The base is (tempo/60) * duration, alpha then specifies the number by \nwhich the base should be multiplied.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.time_shift", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.time_shift", "kind": "variable", "doc": "<p>Time shift of the beat sinusoid from the start.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.duration", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.duration", "kind": "variable", "doc": "<p>Duration of the song in seconds.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.min_delta", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.min_delta", "kind": "variable", "doc": "<p>Minimum delta for peak picking. Peak picking algorithm slowly makes delta\nsmaller so that the correct number of peaks is extracted. When delta reaches min_delta, the algorithm\nends even before finding the minimal number of peaks.</p>\n", "annotation": ": float"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.click_times_sec", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.click_times_sec", "kind": "variable", "doc": "<p>Click times. They represent a metronome set to the defined tempo that is started from time 0. Beat tracking \nworks by shifting these click times and finding the best time shift so that the most click time align with \nnote onset candidates.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.peaks", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.peaks", "kind": "variable", "doc": "<p>Peaks in novelty function (their frame position). Peaks represent note onset candidates.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.peak_times", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.peak_times", "kind": "variable", "doc": "<p>Peak times in seconds.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.beat_times", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.beat_times", "kind": "variable", "doc": "<p>Beat times in seconds.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.tolerance", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.tolerance", "kind": "variable", "doc": "<p>Length of tolerance interval in milliseconds for scoring.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.rhythmic_onsets", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.rhythmic_onsets", "kind": "variable", "doc": "<p>Note onset times that belong to some rhythmic pattern of the song.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.rhythm.rhythm_recognition.RhythmTracker.find_rhythmic_onsets", "modulename": "RhythmRecognition.rhythm.rhythm_recognition", "qualname": "RhythmTracker.find_rhythmic_onsets", "kind": "function", "doc": "<p>Extract rhythmic onsets in the song by dividing it into chorus and verse (and possibly other part types)\nparts and extracting note onsets from each aprt separately.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<blockquote>\n  <p>Rhythmic note onsets.</p>\n</blockquote>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.tempo", "modulename": "RhythmRecognition.tempo", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.tempo.autocorrelation", "modulename": "RhythmRecognition.tempo.autocorrelation", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.tempo.autocorrelation.AutocorrelationTempogram", "modulename": "RhythmRecognition.tempo.autocorrelation", "qualname": "AutocorrelationTempogram", "kind": "class", "doc": "<p>Class for computing the autocorrelation tempogram.</p>\n\n<p>The <strong>autocorrelation tempogram</strong> is based on autocorrelation, which  measures the\nsimilarity between a signal and a time-shifted version of it. If we apply autocorrelation locally\n(short-time autocorrelation) to the novelty function of the audio signal, we can then compute the\nautocorrelation tempogram, which will reveal dominant tempi.</p>\n", "bases": "RhythmRecognition.tempo.tempogram.Tempogram"}, {"fullname": "RhythmRecognition.tempo.autocorrelation.AutocorrelationTempogram.__init__", "modulename": "RhythmRecognition.tempo.autocorrelation", "qualname": "AutocorrelationTempogram.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>similarity</strong>:  BPM tolerance that specifies which BPM values belong to the same group.</li>\n<li><strong>number_of_dominant_values</strong>:  How many dominant BPM values should be extracted for later computations.</li>\n<li><strong>lower_bound</strong>:  Lowest possible BPM value that will be considered.</li>\n<li><strong>upper_bound</strong>:  Highest possible BPM value that will be considered.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">similarity</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">number_of_dominant_values</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">lower_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">200</span></span>)</span>"}, {"fullname": "RhythmRecognition.tempo.fourier", "modulename": "RhythmRecognition.tempo.fourier", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.tempo.fourier.FourierTempogram", "modulename": "RhythmRecognition.tempo.fourier", "qualname": "FourierTempogram", "kind": "class", "doc": "<p>Class for computing the Fourier tempogram.\nThe <strong>Fourier tempogram</strong> is computed by applying Short-time Fourier transform (STFT) on\na novelty function computed from the audio signal.</p>\n", "bases": "RhythmRecognition.tempo.tempogram.Tempogram"}, {"fullname": "RhythmRecognition.tempo.fourier.FourierTempogram.__init__", "modulename": "RhythmRecognition.tempo.fourier", "qualname": "FourierTempogram.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>similarity</strong>:  BPM tolerance that specifies which BPM values belong to the same group.</li>\n<li><strong>number_of_dominant_values</strong>:  How many dominant BPM values should be extracted for later computations.</li>\n<li><strong>lower_bound</strong>:  Lowest possible BPM value that will be considered.</li>\n<li><strong>upper_bound</strong>:  Highest possible BPM value that will be considered.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">similarity</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">number_of_dominant_values</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">lower_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">200</span></span>)</span>"}, {"fullname": "RhythmRecognition.tempo.hybrid", "modulename": "RhythmRecognition.tempo.hybrid", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.tempo.hybrid.HybridTempogram", "modulename": "RhythmRecognition.tempo.hybrid", "qualname": "HybridTempogram", "kind": "class", "doc": "<p>Class for computing the hybrid tempogram.</p>\n\n<p>The <strong>hybrid tempogram</strong> combines the Fourier and autocorrelation tempograms. It is\na simple element-wise product of both tempograms with some added post-processing for\nenhancing dominant tempi.</p>\n", "bases": "RhythmRecognition.tempo.tempogram.Tempogram"}, {"fullname": "RhythmRecognition.tempo.hybrid.HybridTempogram.__init__", "modulename": "RhythmRecognition.tempo.hybrid", "qualname": "HybridTempogram.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>similarity</strong>:  BPM tolerance that specifies which BPM values belong to the same group.</li>\n<li><strong>number_of_dominant_values</strong>:  How many dominant BPM values should be extracted for later computations.</li>\n<li><strong>lower_bound</strong>:  Lowest possible BPM value that will be considered.</li>\n<li><strong>upper_bound</strong>:  Highest possible BPM value that will be considered.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">similarity</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">number_of_dominant_values</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">lower_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">200</span></span>)</span>"}, {"fullname": "RhythmRecognition.tempo.hybrid.HybridTempogram.gamma", "modulename": "RhythmRecognition.tempo.hybrid", "qualname": "HybridTempogram.gamma", "kind": "variable", "doc": "<p>Compression factor for logarithmic compression.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.tempo.tempogram", "modulename": "RhythmRecognition.tempo.tempogram", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram", "kind": "class", "doc": "<p>Base class for specific tempogram implementations.</p>\n\n<p>A <strong>tempogram</strong> indicates specific tempo relevance for each time instance in a song.\nOnly an interval of reasonable tempi should be considered for tempo analysis, as too high values\nor too small values do not really make sense in terms of musical tempo analysis.</p>\n\n<p>We assume that the input songs have constant tempo and the BPM value is an integer.</p>\n"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.__init__", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.__init__", "kind": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>novelty_function</strong>:  Novelty function of the input audio signal.</li>\n<li><strong>similarity</strong>:  BPM tolerance that specifies which BPM values belong to the same group.</li>\n<li><strong>number_of_dominant_values</strong>:  How many dominant BPM values should be extracted for later computations.</li>\n<li><strong>lower_bound</strong>:  Lowest possible BPM value that will be considered.</li>\n<li><strong>upper_bound</strong>:  Highest possible BPM value that will be considered.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">novelty_function</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>,</span><span class=\"param\">\t<span class=\"n\">similarity</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">number_of_dominant_values</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">lower_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">upper_bound</span><span class=\"p\">:</span> <span class=\"nb\">int</span> <span class=\"o\">=</span> <span class=\"mi\">200</span></span>)</span>"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.novelty_function", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.novelty_function", "kind": "variable", "doc": "<p>Novelty function of the input audio signal.</p>\n", "annotation": ": numpy.ndarray"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.similarity", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.similarity", "kind": "variable", "doc": "<p>BPM tolerance that specifies which BPM values belong to the same group.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.number_of_dominant_values", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.number_of_dominant_values", "kind": "variable", "doc": "<p>How many dominant BPM values should be extracted for later computations.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.tempogram", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.tempogram", "kind": "variable", "doc": "<p>Tempogram of the input audio file.</p>\n", "annotation": ": numpy.ndarray | None"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.bpm_values", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.bpm_values", "kind": "variable", "doc": "<p>List of dominant BPM values.</p>\n", "annotation": ": []"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.tempo", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.tempo", "kind": "variable", "doc": "<p>The most dominant BPM value that should indicate tempo of the song.</p>\n", "annotation": ": int | None"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.lower_bound", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.lower_bound", "kind": "variable", "doc": "<p>Lowest possible BPM value that will be considered in tempo analysis.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.upper_bound", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.upper_bound", "kind": "variable", "doc": "<p>Highest possible BPM value that will be considered in tempo analysis.</p>\n", "annotation": ": int"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.get_tempogram", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.get_tempogram", "kind": "function", "doc": "<p>Get the computed tempogram.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>:</span></span>", "funcdef": "def"}, {"fullname": "RhythmRecognition.tempo.tempogram.Tempogram.get_tempo", "modulename": "RhythmRecognition.tempo.tempogram", "qualname": "Tempogram.get_tempo", "kind": "function", "doc": "<p>Get the most dominant tempo.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">int</span>:</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();